{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_batcher import get_batch_generator\n",
    "from src.data.vocab import get_glove\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_context_path = os.path.join(\"data\", \"train.context\")\n",
    "train_qn_path = os.path.join(\"data\", \"train.question\")\n",
    "train_ans_path = os.path.join(\"data\", \"train.span\")\n",
    "dev_context_path = os.path.join(\"data\", \"dev.context\")\n",
    "dev_qn_path = os.path.join(\"data\", \"dev.question\")\n",
    "dev_ans_path = os.path.join(\"data\", \"dev.span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GLoVE vectors from file: data/glove.6B.100d.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffc7deede9d411fbefebb248c0abbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glove_path = os.path.join(\"data\", \"glove.6B.{}d.txt\".format(100))\n",
    "\n",
    "emb_matrix, word2id, id2word = get_glove(glove_path, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PAD = '<pad>'\n",
    "_UNK = '<unk>'\n",
    "characters = 'abcdefghijklmnopqrstuvwxyz0123456789,.<>:;{}[]\\|=+_-()*&?^%$#@!`~\\n/\\\"\\'\\\\'\n",
    "characters = list([_PAD, _UNK]) + list(characters)\n",
    "char2id = {character: i for i, character in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "klm = get_batch_generator(word2id, char2id, train_context_path, \n",
    "                          train_qn_path, train_ans_path, \n",
    "                          batch_size=32, context_len=625, \n",
    "                          question_len=50, character_len=20, discard_long=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from src.layers.embedding import CharacterConvEmbedding\n",
    "from src.layers.attention import BasicAttention, BiAttention, CoAttention\n",
    "from src.layers.network import EmbedText, Encoder, DynamicPointingDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_args = {'vocab_size': 71, 'embedding_dim': 8, 'padding_idx':0}\n",
    "char_conv_args = {'char_embed_dim':8, 'embedding_dim':100, 'kernel_sizes':[2, 3, 4], 'num_filters':50, 'use_cuda':True}\n",
    "word_args = {'vocab_size':4e5, 'embedding_dim':100, 'embeddings':emb_matrix, 'trainable':False, 'padding_idx':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_args, char_conv_args, shared=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = Encoder(word_args=word_args, char_args=char_conv_args, \n",
    "                               hidden_dim=200, shared=shared, use_cuda=True)\n",
    "        \n",
    "        self.attention = CoAttention(hidden_dim=200, use_cuda=True)\n",
    "                \n",
    "    def forward(self, q_w, c_w, q_c, c_c):\n",
    "        question_encoded, context_encoded = self.encoder(q_w, c_w, q_c, c_c)\n",
    "        U = self.attention(question_encoded, context_encoded)\n",
    "        return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedtext = EmbedText(word_args, char_args, shared=True)\n",
    "\n",
    "encoder_net = Model(word_args, char_conv_args, shared=True)\n",
    "#encoder_net = torch.nn.DataParallel(encoder_net, device_ids=[0, 1])\n",
    "decoder_net = DynamicPointingDecoder(400, pool_size=16, p=0.25, max_iter=4, use_cuda=True)\n",
    "#decoder_net = torch.nn.DataParallel(decoder_net, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "enc_optim = optim.Adam(filter(lambda p: p.requires_grad, encoder_net.parameters()), lr=LR, weight_decay=1e-4)\n",
    "dec_optim = optim.Adam(decoder_net.parameters(),lr=LR, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 51.07040786743164\n",
      "1 47.55656433105469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-37a90d9268a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0menc_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mdec_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlptorch/env/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlptorch/env/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "losses_array = []\n",
    "\n",
    "for i, batch in enumerate(klm):\n",
    "      \n",
    "    question_words_embed, context_words_embed, question_characters_embed, context_character_embed = embedtext(\n",
    "        th.from_numpy(batch.qn_ids).type(torch.LongTensor), \n",
    "          th.from_numpy(batch.context_ids).type(torch.LongTensor), \n",
    "          th.from_numpy(batch.qn_char_ids).type(torch.LongTensor), \n",
    "          th.from_numpy(batch.context_char_ids).type(torch.LongTensor))\n",
    "    \n",
    "    question_words = question_words_embed.cuda().type(torch.cuda.FloatTensor)\n",
    "    context_words = context_words_embed.cuda().type(torch.cuda.FloatTensor)\n",
    "    question_characters = question_characters_embed.cuda().type(torch.cuda.FloatTensor)\n",
    "    context_characters = context_character_embed.cuda().type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    starts = th.from_numpy(batch.ans_span)[:,0].cuda().type(torch.cuda.LongTensor)\n",
    "    ends = th.from_numpy(batch.ans_span)[:,1].cuda().type(torch.cuda.LongTensor)\n",
    "    \n",
    "    strt = batch.ans_span[:,0]\n",
    "    end = batch.ans_span[:,1]\n",
    "    \n",
    "    u = end[np.where(end > 625)]\n",
    "    o = strt[np.where(strt > 625)]\n",
    "    if len(u) != 0:\n",
    "        print (i, u)\n",
    "    if len(o) != 0:\n",
    "        print (i, o)    \n",
    "    encoder_net.zero_grad()\n",
    "    decoder_net.zero_grad()\n",
    "    \n",
    "    inputs = [question_words, context_words, question_characters, context_characters]\n",
    "    \n",
    "    U = encoder_net(*inputs)\n",
    "    _, _, entropies = decoder_net(U, is_training=True)\n",
    "    \n",
    "    s_ents, e_ents = list(zip(*entropies))\n",
    "    \n",
    "    loss_start, loss_end = 0, 0\n",
    "    for m in range(len(entropies)):\n",
    "        loss_start += loss_fn(s_ents[m], starts.view(-1))\n",
    "        loss_end += loss_fn(e_ents[m], ends.view(-1))\n",
    "        \n",
    "    loss = loss_start + loss_end\n",
    "    \n",
    "    loss.backward()\n",
    "    enc_optim.step()\n",
    "    dec_optim.step()\n",
    "    \n",
    "    losses_array.append(loss.item())\n",
    "    print (i, loss.item())\n",
    "    \n",
    "np.save('losses.npy', losses_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51.07040786743164, 47.55656433105469]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptorch",
   "language": "python",
   "name": "nlptorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
